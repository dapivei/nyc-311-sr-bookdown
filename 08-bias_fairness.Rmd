# Bias y Fairness {#biasFairness}

<div align="justify">
Con el fin de identificar si los modelos y predicciones, desarrollados para este proyecto, brindan ventajas o desventajas sistemáticas a ciertos grupos (distritos), ya sea por algún tipo de prejuicio o por un sobre/sub sampleo, utilizamos [aequitas](http://www.datasciencepublicpolicy.org/projects/aequitas/), un *tool kit* que permite auditar modelos de *machine learning*, en términos de discriminación y sesgo, para tomar decisiones informadas y **equitativas**, que no solamente prioricen el desempeño del modelo.

## Atributo protegido

Al no contar con datos personales (como raza o género de los solicitantes del servicio de quejas NYC 311), decidimos identificar a la variable *borough* como atributo protegido; este atributo consta de 6 grupos o valores únicos: Brooklyn, Bronx, Queens, Manhattan, No especificado, Staten Island. 

**Mapa de la ciudad de Nueva York**
<div align="center">

<image width="500" height="500" src="./images/nyc_boroughs.png">

</div>


Fuente: [alamy](https://www.alamy.com/stock-image-modern-city-map-new-york-city-of-the-usa-with-boroughs-and-titles-160125612.html)

Cambiaremos los valores de la columna borough para facilitar la interpretación y asegurar de que sea considerada como una variable categórica en el reporte de Aequitas de la siguiente manera:

+ borough_bronx = A 
+ borough_brooklyn = B 
+ borough_manhattan = C 
+ borough_queens = D 
+ borough_staten island = E 
+ borough_unspecified  = F 

 **Diferencias en predicciones por distrito**
<div align="center">

<image width="300" height="250" src="./images/score_borough.png">

</div>

En la gráfica anterior, notamos que hay una diferencia en la distribución de las predicciones por distrito. Por ejemplo, una proporción muy pequeña de las predicciones de _Bronx_  (en comparación con las predicciones totales de Bronx), están por encima de la media; al contrario, para otros distritos como Queens o Manhattan, una proporción considerable de sus predicciones totales predicen 1: predicciones por encima de la media.

## Grupo de referencia

El grupo de referencia es Brooklyn, mismo que fue escogido por tener el mayor tamaño entre todos los grupos existentes, con un valor aproximado de $6.72$ millones de quejas del total de $22,601,839$.


## Métricas de equidad y sesgo

Probamos las siguientes métricas de equidad y sesgo:

* False Positive Parity: auditamos si el modelo genera, proporcionalmente, la misma cantidad de errores falsos positivos.
* False Negative Parity: auditamos si el modelo genera, proporcionalmente, la misma cantidad de errores falsos negativos.

## Input

Para obtener los resultados preliminares, subimos un archivo .csv al sitio-web de Aequitas, con las siguientes columnas:

+ Score (binaria): predicción generada por el modelo que queremos auditar.

+ label_value (binaria): etiqueta real asociada a la observación.

+ columna de atributos: los que vamos a auditar por sesgo; cada fila estaba asociada a una queja de *ruido* a la agencia *NYPD*.

| score |etiqueta_binaria | atributo_protegido|
|-|-|-|
|0|1|brooklyn|
|1|0|queens|
|$\vdots$|$\vdots$|$\vdots$|

## Resultados

A manera de ejemplo, a continuación presentamos los resultados de uno de los modelos entrenados.

> **RandomForestClassifier**(bootstrap=True, ccp_alpha=0.0, class_weight=None,criterion='gini', max_depth=20, max_features='auto', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None,         min_samples_leaf=1, min_samples_split=2,                  min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=-1,           oob_score=False, random_state=None, verbose=0, warm_start=False)



 **Diferencias en predicciones por distrito**
<div align="center">

<image width="700" height="400" src="./images/bias_metrics.png">

</div>


Vemos que los distritos _D, E, F_  tienen false positive rates (fpr) de  13%, 18% y 11% respectivamente, mientras que los distritos _A, B, C_ tiene fpr de 0% o 3%. Esto significa que los distritos _D, E, F_ tienen más probabilidad de que sus predicciones sean falsamente etiquetadas por encima del promedio, en comparación con los otros distritos. Por otro lado, los false ommision rates (for)- entendidos como las predicciones que deberían ser etiquetadas por encima del promedio y no lo son-son muchísimo más similares entre los distritos _D, E, F_.

Finalmente, con la gráfica de False Negative Rate (fnr), observamos que las predicciones asociadas con el distrito D, con mayor frecuencia genera prediciones incorrectas (falsas negativas.). Por la coloración oscura de barra "D", identificamos que Queens es una de las poblaciones más grandes dentro del dataset.


 **Diferencias en predicciones por paridad entre distrito**
 
A continuación, mostramos otras pruebas de bias y fairness que no fueron consideradas al momento de escoger nuestro mejor modelo, sin embargo, nos interesaría explorar y analizar a mayor profundidad estas métricas en un futuro próximo.

<div align="center">

<image width="613" height="400" src="./images/disparity_metrics_i.png">
<image width="600" height="190" src="./images/disparity_metrics_ii.png">

</div>



<div align="center">

<image width="700" height="400" src="./images/disparity_metrics_iii.png">

</div>


<div align="center">

<image width="600" height="400" src="./images/disparity_metrics_iv.png">
<image width="600" height="190" src="./images/disparity_metrics_v.png">
</div>



</div>
