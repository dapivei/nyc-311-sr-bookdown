[
["biasFairness.html", "Capítulo 9 Bias y Fairness 9.1 Atributo protegido 9.2 Grupo de referencia 9.3 Métricas de equidad y sesgo 9.4 Input 9.5 Resultados", " Capítulo 9 Bias y Fairness Con el fin de identificar si los modelos y predicciones, desarrollados para este proyecto, brindan ventajas o desventajas sistemáticas a ciertos grupos (distritos), ya sea por algún tipo de prejuicio o por un sobre/sub sampleo, utilizamos aequitas, un tool kit que permite auditar modelos de machine learning, en términos de discriminación y sesgo, para tomar decisiones informadas y equitativas, que no solamente prioricen el desempeño del modelo. 9.1 Atributo protegido Al no contar con datos personales (como raza o género de los solicitantes del servicio de quejas NYC 311), decidimos identificar a la variable borough como atributo protegido; este atributo consta de 6 grupos o valores únicos: Brooklyn, Bronx, Queens, Manhattan, No especificado, Staten Island. Mapa de la ciudad de Nueva York Fuente: alamy Cambiaremos los valores de la columna borough para facilitar la interpretación y asegurar de que sea considerada como una variable categórica en el reporte de Aequitas de la siguiente manera: borough_bronx = A borough_brooklyn = B borough_manhattan = C borough_queens = D borough_staten island = E borough_unspecified = F Diferencias en predicciones por distrito En la gráfica anterior, notamos que hay una diferencia en la distribución de las predicciones por distrito. Por ejemplo, una proporción muy pequeña de las predicciones de Bronx (en comparación con las predicciones totales de Bronx), están por encima de la media; al contrario, para otros distritos como Queens o Manhattan, una proporción considerable de sus predicciones totales predicen 1: predicciones por encima de la media. 9.2 Grupo de referencia El grupo de referencia es Brooklyn, mismo que fue escogido por tener el mayor tamaño entre todos los grupos existentes, con un valor aproximado de \\(6.72\\) millones de quejas del total de \\(22,601,839\\). 9.3 Métricas de equidad y sesgo Probamos las siguientes métricas de equidad y sesgo: False Positive Parity: auditamos si el modelo genera, proporcionalmente, la misma cantidad de errores falsos positivos. False Negative Parity: auditamos si el modelo genera, proporcionalmente, la misma cantidad de errores falsos negativos. 9.4 Input Para obtener los resultados preliminares, subimos un archivo .csv al sitio-web de Aequitas, con las siguientes columnas: Score (binaria): predicción generada por el modelo que queremos auditar. label_value (binaria): etiqueta real asociada a la observación. columna de atributos: los que vamos a auditar por sesgo; cada fila estaba asociada a una queja de ruido a la agencia NYPD. score etiqueta_binaria atributo_protegido 0 1 brooklyn 1 0 queens \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) 9.5 Resultados A manera de ejemplo, a continuación presentamos los resultados de uno de los modelos entrenados. RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,criterion=‘gini’, max_depth=20, max_features=‘auto’, max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=-1, oob_score=False, random_state=None, verbose=0, warm_start=False) Diferencias en predicciones por distrito Vemos que los distritos D, E, F tienen false positive rates (fpr) de 13%, 18% y 11% respectivamente, mientras que los distritos A, B, C tiene fpr de 0% o 3%. Esto significa que los distritos D, E, F tienen más probabilidad de que sus predicciones sean falsamente etiquetadas por encima del promedio, en comparación con los otros distritos. Por otro lado, los false ommision rates (for)- entendidos como las predicciones que deberían ser etiquetadas por encima del promedio y no lo son-son muchísimo más similares entre los distritos D, E, F. Finalmente, con la gráfica de False Negative Rate (fnr), observamos que las predicciones asociadas con el distrito D, con mayor frecuencia genera prediciones incorrectas (falsas negativas.). Por la coloración oscura de barra “D”, identificamos que Queens es una de las poblaciones más grandes dentro del dataset. Diferencias en predicciones por paridad entre distrito A continuación, mostramos otras pruebas de bias y fairness que no fueron consideradas al momento de escoger nuestro mejor modelo, sin embargo, nos interesaría explorar y analizar a mayor profundidad estas métricas en un futuro próximo. "]
]
